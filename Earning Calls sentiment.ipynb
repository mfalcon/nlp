{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AA_APIKEY = 'KTTAYRUUXWIVVFBM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import cmudict\n",
    "cmud = cmudict.dict()\n",
    "#contador de silabas: https://stackoverflow.com/questions/405161/detecting-syllables-in-a-word\n",
    "def nsyl(word):\n",
    "    if word.lower() in cmud:\n",
    "        return [len(list(y for y in x if y[-1].isdigit())) for x in cmud[word.lower()]] \n",
    "    return [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#cargo el diccionario financiero de Loughran Mc Donald\n",
    "lm_masterdic = {}\n",
    "with open('corpus/LoughranMcDonald_MasterDictionary_2014.csv') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        lm_masterdic[row['Word'].lower()] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Word', 'CHALLENGES'),\n",
       "             ('Sequence Number', '11487'),\n",
       "             ('Word Count', '310301'),\n",
       "             ('Word Proportion', '2.18E-05'),\n",
       "             ('Average Proportion', '1.54E-05'),\n",
       "             ('Std Dev', '5.59E-05'),\n",
       "             ('Doc Count', '141958'),\n",
       "             ('Negative', '2009'),\n",
       "             ('Positive', '0'),\n",
       "             ('Uncertainty', '0'),\n",
       "             ('Litigious', '0'),\n",
       "             ('Constraining', '0'),\n",
       "             ('Superfluous', '0'),\n",
       "             ('Interesting', '0'),\n",
       "             ('Modal', '0'),\n",
       "             ('Irr_Verb', '0'),\n",
       "             ('Harvard_IV', '2'),\n",
       "             ('Syllables', '3'),\n",
       "             ('Source', '12of12inf')])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_masterdic['challenges']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#cargo todas las earning calls\n",
    "ecalls = glob.glob('data/*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#expresion regular para solo obtener palabras e ignorar numeros y puntuacion\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ecalls_data = []\n",
    "negative_words_text = ''\n",
    "positive_words_text = ''\n",
    "for ec in ecalls:\n",
    "    ticker = re.search(r'\\((?P<ticker>\\w+)\\)', ec).groups()[0]\n",
    "    quarter = re.search(r'Q(?P<quarter>\\d{1}\\s\\d{4})', ec).groups()[0].replace(' ','')\n",
    "    p_fname = ticker + '-' + quarter\n",
    "    ec_text = open(ec).read()\n",
    "    #limpiar seccion Question-and-Answer Session\n",
    "    ec_text = ec_text[:ec_text.find('Question-and-Answer Session')]\n",
    "    ecall_no_punc = tokenizer.tokenize(ec_text)\n",
    "    #acumulo el total de palabras\n",
    "    total_words = [w for w in ecall_no_punc]\n",
    "    #limpio palabras comunes\n",
    "    cleaned_ecall = [w.title() for w in ecall_no_punc if w.lower() not in stopwords.words('english')]\n",
    "    total_tokens = len(cleaned_ecall)\n",
    "    word_count = Counter(cleaned_ecall)\n",
    "    word_sentiment = {}\n",
    "    positive_words = 0\n",
    "    negative_words = 0\n",
    "    complex_words = 0\n",
    "    for word in word_count:\n",
    "        word_proportion = word_count[word] / float(total_tokens)\n",
    "        wl = word.lower()\n",
    "        if wl in lm_masterdic:\n",
    "            if int(lm_masterdic[wl]['Negative']) > 0 and wl not in ['questions', '0']:\n",
    "                word_sentiment[wl] = word_proportion\n",
    "                negative_words += 1\n",
    "                negative_words_text += ' ' + wl\n",
    "                \n",
    "            elif int(lm_masterdic[wl]['Positive']) > 0:\n",
    "                positive_words += 1\n",
    "                positive_words_text += ' ' + wl\n",
    "\n",
    "        if nsyl(word)[0] >= 3:\n",
    "            complex_words += 1\n",
    "                \n",
    "    #negative_proportion = sum([e for e in word_sentiment.values()])\n",
    "    total_count = sum(word_count.values())\n",
    "    #sentimiento del texto, mientras mas alto sea el numero mejor\n",
    "    sentiment = (positive_words / float(negative_words)) / total_count\n",
    "    #proporcion de palabras negativas, mientras mas alto es el numero peor\n",
    "    negative_proportion = float(negative_words) / total_count\n",
    "    \n",
    "    #calculando gunning fog index -> https://en.wikipedia.org/wiki/Gunning_fog_index\n",
    "    sentence_tokenize_list = sent_tokenize(ec_text)\n",
    "    sentence_count = len(sentence_tokenize_list)\n",
    "    avg_sentence_length = len(total_words) / sentence_count\n",
    "    pct_complex_words = complex_words / float(len(total_words)) * 100\n",
    "    #metrica de readabily, cuanto mas alto peor\n",
    "    gunning_fog = (avg_sentence_length + pct_complex_words) * 0.4\n",
    "    \n",
    "    data = {\n",
    "        'fname': p_fname,\n",
    "        'text': ec_text,\n",
    "        'negative_proportion': negative_proportion,\n",
    "        'sentiment': sentiment,\n",
    "        'gunning_fog': gunning_fog\n",
    "    }\n",
    "                                      \n",
    "    ecalls_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neg_rank = sorted(ecalls_data, key=lambda x: x['negative_proportion'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentiment_rank = sorted(ecalls_data, key=lambda x: x['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gunning_fog_rank = sorted(ecalls_data, key=lambda x: x['gunning_fog'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_quarter(date_str):\n",
    "    if date_str.find('-03') != -1:\n",
    "        return date_str.split('-')[0] + '-Q1'\n",
    "    elif date_str.find('-06') != -1:\n",
    "        return date_str.split('-')[0] + '-Q2'\n",
    "    elif date_str.find('-09') != -1:\n",
    "        return date_str.split('-')[0] + '-Q3'\n",
    "    elif date_str.find('-12') != -1:\n",
    "        return date_str.split('-')[0] + '-Q4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Sentiment RankAMZN**** \n",
      "\n",
      "[('AMZN-42016->0.0008291873963515754', ['2016-Q1', -12.169139948808239]),\n",
      " ('AMZN-22017->0.000992063492063492', ['2016-Q4', -10.442966165458426]),\n",
      " ('AMZN-32016->0.001001001001001001', ['2017-Q3', -0.6869834710743778]),\n",
      " ('AMZN-32017->0.001019367991845056', ['2017-Q2', 9.188530692354552]),\n",
      " ('AMZN-22015->0.0010498687664041995', ['2015-Q2', 16.65950013437247]),\n",
      " ('AMZN-32015->0.0010830324909747292', ['2016-Q3', 17.004834968279244]),\n",
      " ('AMZN-22016->0.001085383502170767', ['2015-Q3', 17.92255062314267]),\n",
      " ('AMZN-12015->0.0010903426791277258', ['2017-Q1', 18.225825809807027]),\n",
      " ('AMZN-12017->0.0011086474501108647', ['2015-Q1', 19.896890607378765]),\n",
      " ('AMZN-12016->0.001147227533460803', ['2016-Q2', 20.54780675156661]),\n",
      " ('AMZN-42015->0.0012919896640826874', ['2017-Q4', 21.648723149737346]),\n",
      " ('AMZN-42017->0.00186219739292365', ['2015-Q4', 32.03813319267812])]\n",
      "**** Negative RankAMZN**** \n",
      "\n",
      "[('AMZN-32017->0.009174311926605505', ['2016-Q1', -12.169139948808239]),\n",
      " ('AMZN-32016->0.009009009009009009', ['2016-Q4', -10.442966165458426]),\n",
      " ('AMZN-22017->0.008928571428571428', ['2017-Q3', -0.6869834710743778]),\n",
      " ('AMZN-12017->0.008869179600886918', ['2017-Q2', 9.188530692354552]),\n",
      " ('AMZN-42017->0.008379888268156424', ['2015-Q2', 16.65950013437247]),\n",
      " ('AMZN-42016->0.007462686567164179', ['2016-Q3', 17.004834968279244]),\n",
      " ('AMZN-22016->0.005788712011577424', ['2015-Q3', 17.92255062314267]),\n",
      " ('AMZN-12015->0.005607476635514018', ['2017-Q1', 18.225825809807027]),\n",
      " ('AMZN-12016->0.004780114722753346', ['2015-Q1', 19.896890607378765]),\n",
      " ('AMZN-32015->0.004512635379061372', ['2016-Q2', 20.54780675156661]),\n",
      " ('AMZN-22015->0.004374453193350831', ['2017-Q4', 21.648723149737346]),\n",
      " ('AMZN-42015->0.0034453057708871662', ['2015-Q4', 32.03813319267812])]\n",
      "**** Gunning Fog IndexAMZN**** \n",
      "\n",
      "[('AMZN-42015->10.037063538563183', ['2016-Q1', -12.169139948808239]),\n",
      " ('AMZN-12015->10.568041104688504', ['2016-Q4', -10.442966165458426]),\n",
      " ('AMZN-22016->10.839820022497188', ['2017-Q3', -0.6869834710743778]),\n",
      " ('AMZN-12016->10.940766550522648', ['2017-Q2', 9.188530692354552]),\n",
      " ('AMZN-22015->11.023097974822115', ['2015-Q2', 16.65950013437247]),\n",
      " ('AMZN-32015->11.075984216662185', ['2016-Q3', 17.004834968279244]),\n",
      " ('AMZN-32017->13.47936507936508', ['2015-Q3', 17.92255062314267]),\n",
      " ('AMZN-22017->13.527317829457367', ['2017-Q1', 18.225825809807027]),\n",
      " ('AMZN-32016->13.58477690288714', ['2015-Q1', 19.896890607378765]),\n",
      " ('AMZN-42016->14.136396154706015', ['2016-Q2', 20.54780675156661]),\n",
      " ('AMZN-12017->14.420501422475107', ['2017-Q4', 21.648723149737346]),\n",
      " ('AMZN-42017->14.49132743362832', ['2015-Q4', 32.03813319267812])]\n",
      "**** Sentiment RankEBAY**** \n",
      "\n",
      "[('EBAY-22015->0.0006913170577546022', ['2015-Q3', -59.4289508632138]),\n",
      " ('EBAY-42015->0.0010138248847926267', ['2016-Q1', -13.17321688500728]),\n",
      " ('EBAY-42016->0.001201923076923077', ['2016-Q4', -9.75683890577507]),\n",
      " ('EBAY-22016->0.0013714000748036403', ['2016-Q2', -1.8860016764459315]),\n",
      " ('EBAY-42017->0.0013836042891732965', ['2017-Q4', -1.8720748829953167]),\n",
      " ('EBAY-12016->0.0016061556850440759', ['2015-Q1', 2.7797576621525346]),\n",
      " ('EBAY-32016->0.0016208914903196759', ['2017-Q2', 4.021447721179629]),\n",
      " ('EBAY-12015->0.0016645326504481435', ['2015-Q2', 4.4382801664355105]),\n",
      " ('EBAY-22017->0.0018905633878895912', ['2017-Q3', 10.137457044673537]),\n",
      " ('EBAY-32015->0.001936108422071636', ['2015-Q4', 12.438625204582648]),\n",
      " ('EBAY-32017->0.00274949083503055', ['2017-Q1', 13.068373189626135]),\n",
      " ('EBAY-12017->0.0030400736987563335', ['2016-Q3', 40.538231524989314])]\n",
      "**** Negative RankEBAY**** \n",
      "\n",
      "[('EBAY-42015->0.006021505376344086', ['2015-Q3', -59.4289508632138]),\n",
      " ('EBAY-22015->0.005688551789523584', ['2016-Q1', -13.17321688500728]),\n",
      " ('EBAY-12016->0.005378753922008068', ['2016-Q4', -9.75683890577507]),\n",
      " ('EBAY-22016->0.00526742301458671', ['2016-Q2', -1.8860016764459315]),\n",
      " ('EBAY-32015->0.00484027105517909', ['2017-Q4', -1.8720748829953167]),\n",
      " ('EBAY-42016->0.004836309523809524', ['2015-Q1', 2.7797576621525346]),\n",
      " ('EBAY-32016->0.004502476361999099', ['2017-Q2', 4.021447721179629]),\n",
      " ('EBAY-22017->0.004375303840544483', ['2015-Q2', 4.4382801664355105]),\n",
      " ('EBAY-12015->0.0038732394366197184', ['2017-Q3', 10.137457044673537]),\n",
      " ('EBAY-42017->0.003113109650639917', ['2015-Q4', 12.438625204582648]),\n",
      " ('EBAY-32017->0.0025458248472505093', ['2017-Q1', 13.068373189626135]),\n",
      " ('EBAY-12017->0.0023030861354214646', ['2016-Q3', 40.538231524989314])]\n",
      "**** Gunning Fog IndexEBAY**** \n",
      "\n",
      "[('EBAY-12015->10.711563736726701', ['2015-Q3', -59.4289508632138]),\n",
      " ('EBAY-22015->11.129348148431596', ['2016-Q1', -13.17321688500728]),\n",
      " ('EBAY-42015->11.29478567893452', ['2016-Q4', -9.75683890577507]),\n",
      " ('EBAY-22016->11.655653804205764', ['2016-Q2', -1.8860016764459315]),\n",
      " ('EBAY-42017->11.73425087664871', ['2017-Q4', -1.8720748829953167]),\n",
      " ('EBAY-12016->11.74243045809493', ['2015-Q1', 2.7797576621525346]),\n",
      " ('EBAY-32017->12.04251485852651', ['2017-Q2', 4.021447721179629]),\n",
      " ('EBAY-12017->12.177322279159549', ['2015-Q2', 4.4382801664355105]),\n",
      " ('EBAY-32016->12.239658117424973', ['2017-Q3', 10.137457044673537]),\n",
      " ('EBAY-32015->12.305804624823033', ['2015-Q4', 12.438625204582648]),\n",
      " ('EBAY-22017->12.548161904426085', ['2017-Q1', 13.068373189626135]),\n",
      " ('EBAY-42016->12.746961339159922', ['2016-Q3', 40.538231524989314])]\n",
      "**** Sentiment RankMELI**** \n",
      "\n",
      "[('MELI-22015->0.0006036636136552872', ['2015-Q3', -35.737473535638664]),\n",
      " ('MELI-32015->0.0006534833503807251', ['2016-Q4', -15.586311293723313]),\n",
      " ('MELI-22017->0.0007278835386338187', ['2015-Q1', -4.03383723662568]),\n",
      " ('MELI-12015->0.000816702615542479', ['2016-Q1', 3.0697918488717777]),\n",
      " ('MELI-42015->0.0012350651094106592', ['2017-Q3', 3.2087053571428616]),\n",
      " ('MELI-12017->0.0012626682173118458', ['2015-Q2', 15.654587006203064]),\n",
      " ('MELI-32017->0.001332001332001332', ['2017-Q2', 18.636213174445544]),\n",
      " ('MELI-22016->0.0014414414414414415', ['2016-Q2', 19.36359779380568]),\n",
      " ('MELI-32016->0.0014809478065962217', ['2017-Q4', 21.523191596184304]),\n",
      " ('MELI-42016->0.0016226240148354196', ['2015-Q4', 25.565561168460356]),\n",
      " ('MELI-12016->0.002039592081583683', ['2016-Q3', 31.49214473590674])]\n",
      "**** Negative RankMELI**** \n",
      "\n",
      "[('MELI-22015->0.00832639467110741', ['2015-Q3', -35.737473535638664]),\n",
      " ('MELI-32015->0.008182748039549948', ['2016-Q4', -15.586311293723313]),\n",
      " ('MELI-22017->0.00673758865248227', ['2015-Q1', -4.03383723662568]),\n",
      " ('MELI-22016->0.006486486486486486', ['2016-Q1', 3.0697918488717777]),\n",
      " ('MELI-12015->0.006051975792096832', ['2017-Q3', 3.2087053571428616]),\n",
      " ('MELI-12016->0.00599880023995201', ['2015-Q2', 15.654587006203064]),\n",
      " ('MELI-32016->0.005763688760806916', ['2017-Q2', 18.636213174445544]),\n",
      " ('MELI-12017->0.005615550755939525', ['2016-Q2', 19.36359779380568]),\n",
      " ('MELI-32017->0.005036630036630037', ['2017-Q4', 21.523191596184304]),\n",
      " ('MELI-42016->0.004636068613815485', ['2015-Q4', 25.565561168460356]),\n",
      " ('MELI-42015->0.004537521815008726', ['2016-Q3', 31.49214473590674])]\n",
      "**** Gunning Fog IndexMELI**** \n",
      "\n",
      "[('MELI-12016->12.217740836626243', ['2015-Q3', -35.737473535638664]),\n",
      " ('MELI-22015->13.465736905324613', ['2016-Q4', -15.586311293723313]),\n",
      " ('MELI-32016->13.477304218569357', ['2015-Q1', -4.03383723662568]),\n",
      " ('MELI-32017->13.803034368961551', ['2016-Q1', 3.0697918488717777]),\n",
      " ('MELI-22016->13.804318249038747', ['2017-Q3', 3.2087053571428616]),\n",
      " ('MELI-42016->14.117323702031605', ['2015-Q2', 15.654587006203064]),\n",
      " ('MELI-22017->14.131465444222568', ['2017-Q2', 18.636213174445544]),\n",
      " ('MELI-12017->14.262662013958128', ['2016-Q2', 19.36359779380568]),\n",
      " ('MELI-12015->14.317022269092329', ['2017-Q4', 21.523191596184304]),\n",
      " ('MELI-32015->14.435165349721979', ['2015-Q4', 25.565561168460356]),\n",
      " ('MELI-42015->14.73248315519349', ['2016-Q3', 31.49214473590674])]\n"
     ]
    }
   ],
   "source": [
    "for ticker in [\"AMZN\",\"EBAY\",\"MELI\"]:\n",
    "    \n",
    "    t_neg_rank = [nr['fname'] + '->' + str(nr['negative_proportion']) for nr in neg_rank if nr['fname'][:4] == ticker]\n",
    "    t_sent_rank = [nr['fname'] + '->' + str(nr['sentiment']) for nr in sentiment_rank if nr['fname'][:4] == ticker]\n",
    "    t_gunning_fog_index = [nr['fname'] + '->' + str(nr['gunning_fog']) for nr in gunning_fog_rank if nr['fname'][:4] == ticker]\n",
    "    \n",
    "    data = requests.get('https://www.alphavantage.co/query?function=TIME_SERIES_MONTHLY&symbol=%s&apikey=%s' % (ticker, AA_APIKEY))\n",
    "    monthly_data = data.json()['Monthly Time Series']\n",
    "    \n",
    "    q_performance = sorted([(get_quarter(k[:-3]),float(v['4. close'])) for k,v in monthly_data.items() if datetime.strptime(k, \"%Y-%m-%d\").year >= 2014 and  datetime.strptime(k, \"%Y-%m-%d\").month % 3 == 0])\n",
    "    ticker_perf = []\n",
    "    for idx, e in enumerate(q_performance):\n",
    "        if idx == 0:\n",
    "            pass\n",
    "        else:\n",
    "            perc_diff = ((e[1]-q_performance[idx-1][1]) / q_performance[idx-1][1]) * 100\n",
    "            ticker_perf.append([e[0], perc_diff])\n",
    "    \n",
    "    #ignoro 2014 y 2018 en perc_diff\n",
    "    \n",
    "    print('**** Sentiment Rank ' + ticker + '**** \\n')\n",
    "    pprint(list(zip(t_sent_rank,sorted(ticker_perf[3:-1], key=lambda x:x[1]))))\n",
    "    \n",
    "    print('**** Negative Rank ' + ticker + '**** \\n')\n",
    "    pprint(list(zip(t_neg_rank,sorted(ticker_perf[3:-1], key=lambda x:x[1]))))\n",
    "    \n",
    "    print('**** Gunning Fog Index ' + ticker + '**** \\n')\n",
    "    pprint(list(zip(t_gunning_fog_index,sorted(ticker_perf[3:-1], key=lambda x:x[1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
